{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character_12_thaa\n",
      "character_27_ra\n",
      "character_13_daa\n",
      "character_21_pa\n",
      "character_14_dhaa\n",
      "character_25_ma\n",
      "character_30_motosaw\n",
      "character_16_tabala\n",
      "character_20_na\n",
      "digit_8\n",
      "digit_5\n",
      "character_4_gha\n",
      "character_32_patalosaw\n",
      "character_18_da\n",
      "character_9_jha\n",
      "character_33_ha\n",
      "digit_2\n",
      "character_26_yaw\n",
      "digit_7\n",
      "digit_1\n",
      "digit_4\n",
      "character_31_petchiryakha\n",
      "digit_9\n",
      "character_3_ga\n",
      "character_29_waw\n",
      "character_6_cha\n",
      "character_8_ja\n",
      "character_23_ba\n",
      "character_7_chha\n",
      "character_28_la\n",
      "character_22_pha\n",
      "character_35_tra\n",
      "digit_3\n",
      "digit_6\n",
      "character_34_chhya\n",
      "character_24_bha\n",
      "character_11_taamatar\n",
      "digit_0\n",
      "character_17_tha\n",
      "character_10_yna\n",
      "character_36_gya\n",
      "character_19_dha\n",
      "character_5_kna\n",
      "character_2_kha\n",
      "character_15_adna\n",
      "character_1_ka\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(\"DevanagariHandwrittenCharacterDataset/Train\"):\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    labels=[]\n",
    "    img_data=[]\n",
    "    label_idx=[]\n",
    "    i=-1\n",
    "    for folder in os.listdir(path):\n",
    "        labels.append(folder)\n",
    "        i+=1\n",
    "        for train_image in os.listdir(path + \"/\" +folder):\n",
    "            image = cv2.imread(path + \"/\" +folder + \"/\" +train_image, cv2.IMREAD_GRAYSCALE)\n",
    "            image=cv2.resize(image,(32,32))\n",
    "            img_data.append(image)\n",
    "            label_idx.append(i)\n",
    "    return np.array(labels),np.array(img_data),np.array(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name,X_train,y_train=load_images(\"DevanagariHandwrittenCharacterDataset/Train\")\n",
    "_,X_test,y_test=load_images(\"DevanagariHandwrittenCharacterDataset/Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78200 13800\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train),len(y_test))\n",
    "print(len(label_name))\n",
    "#one hot encoding\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train,46)\n",
    "y_test = np_utils.to_categorical(y_test,46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#one hot vectors\n",
    "print(y_train[0:3,:])\n",
    "print(y_test[0:3,:])\n",
    "X_train = X_train.reshape(X_train.shape[0],32,32,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "sample=mpimg.imread(\"DevanagariHandwrittenCharacterDataset/Train/character_11_taamatar/214.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sample.shape)\n",
    "plot=plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train conv network now!\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78200 samples, validate on 13800 samples\n",
      "Epoch 1/8\n",
      "78200/78200 [==============================] - 374s 5ms/step - loss: 2.3590 - acc: 0.3313 - val_loss: 0.8123 - val_acc: 0.8728\n",
      "Epoch 2/8\n",
      "78200/78200 [==============================] - 374s 5ms/step - loss: 1.6895 - acc: 0.4673 - val_loss: 0.5278 - val_acc: 0.9045\n",
      "Epoch 3/8\n",
      "78200/78200 [==============================] - 375s 5ms/step - loss: 1.5013 - acc: 0.5110 - val_loss: 0.3704 - val_acc: 0.9359\n",
      "Epoch 4/8\n",
      "78200/78200 [==============================] - 397s 5ms/step - loss: 1.4081 - acc: 0.5344 - val_loss: 0.3022 - val_acc: 0.9386\n",
      "Epoch 5/8\n",
      "78200/78200 [==============================] - 398s 5ms/step - loss: 1.3376 - acc: 0.5519 - val_loss: 0.2761 - val_acc: 0.9448\n",
      "Epoch 6/8\n",
      "78200/78200 [==============================] - 380s 5ms/step - loss: 1.2930 - acc: 0.5674 - val_loss: 0.2457 - val_acc: 0.9488\n",
      "Epoch 7/8\n",
      "78200/78200 [==============================] - 388s 5ms/step - loss: 1.2677 - acc: 0.5703 - val_loss: 0.2251 - val_acc: 0.9522\n",
      "Epoch 8/8\n",
      "78200/78200 [==============================] - 398s 5ms/step - loss: 1.2237 - acc: 0.5836 - val_loss: 0.2157 - val_acc: 0.9549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3efe094390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#2 conv layers , \n",
    "model.add(Conv2D(32,(2,2),input_shape=(32,32,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#to pass to dense we need to flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#2 dense layers for full connection\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(46))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=8,verbose=True,batch_size=32,validation_data=(X_test,y_test))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13800/13800 [==============================] - 17s 1ms/step\n",
      "Loss:  0.21566840724236724\n",
      "Accuracy:  0.9548550724637681\n",
      "78200/78200 [==============================] - 96s 1ms/step\n",
      "Loss:  0.19891996598276107\n",
      "Accuracy:  0.9620716112470993\n"
     ]
    }
   ],
   "source": [
    "#scoring_on_test_set\n",
    "score = model.evaluate(X_test,y_test)\n",
    "print(\"Loss: \",score[0])\n",
    "print(\"Accuracy: \",score[1]) \n",
    "\n",
    "#scoring_on_train_set\n",
    "score = model.evaluate(X_train,y_train)\n",
    "print(\"Loss: \",score[0])\n",
    "print(\"Accuracy: \",score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "from keras.models import model_from_json \n",
    "model_json=model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print('saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
